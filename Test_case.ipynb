{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of the neural network for the San Pedro River Basin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook runs the neural network on some test cases and compares the predictions with MODFLOW calculations in the attached data 'Well_data_examps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "import skfmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some functions, that we use to create input data for the neural network. Loaded text files contain data on stream locations and hydraulic conductivities that are extracted from the MODFLOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance to stream \n",
    "def dist():\n",
    "    data_str = np.loadtxt('str.txt')\n",
    "    row = (data_str[:,1])\n",
    "    col = (data_str[:,2])\n",
    "\n",
    "    row = row.astype(int)\n",
    "    col = col.astype(int)\n",
    "\n",
    "    data_hk = np.loadtxt('hyd_kon')\n",
    "    data_hk = data_hk[::-1]\n",
    "    hyk = np.flipud((data_hk))\n",
    "\n",
    "    xmax = 80000\n",
    "    ymax = 110000\n",
    "    X, Y = np.meshgrid(np.linspace(0,xmax,320), np.linspace(ymax,0,440))\n",
    "    phi =  -1* np.ones_like(X)\n",
    "    phi[row,col] = 1\n",
    "\n",
    "    d = skfmm.distance(phi,dx=250) \n",
    "    d = -d\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance to well\n",
    "def well_dist(row,col):    \n",
    "    xmax = 80000\n",
    "    ymax = 110000\n",
    "    X, Y = np.meshgrid(np.linspace(0,xmax,320), np.linspace(ymax,0,440))\n",
    "    phi =  -1* np.ones_like(X)\n",
    "    phi[row,col] = 1\n",
    "\n",
    "    d_well = skfmm.distance(phi,dx=250) \n",
    "    d_well = -d_well\n",
    "    return d_well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#travel time from to well\n",
    "def travel_time(row,col,h0):\n",
    "    result = np.where(h0 == -999)\n",
    "    result = np.array(result)\n",
    "    data_hk = np.loadtxt('hyd_kon')\n",
    "    data_hk = data_hk[::-1]\n",
    "    hyk = np.flipud((data_hk))\n",
    "    hyk +=0.1\n",
    "\n",
    "    hk_smooth = scipy.ndimage.filters.gaussian_filter(hyk,(6.5,6.5))\n",
    "    hk_smooth[result[0,:],result[1,:]] = -2\n",
    "\n",
    "    hyk = np.flipud((data_hk))\n",
    "\n",
    "    xmax = 80000\n",
    "    ymax = 110000\n",
    "    X, Y = np.meshgrid(np.linspace(0,320,320), np.linspace(440,0,440))\n",
    "    #X = X[::-1]\n",
    "    #Y = Y[::-1]\n",
    "    phi =  np.ones_like(hyk)*hyk\n",
    "    phi[phi == 0] = 0\n",
    "    phi[phi != 0] = -1\n",
    "    phi[row,col] = 1\n",
    "\n",
    "    speed=np.ones_like(phi)*hk_smooth\n",
    "    t = skfmm.travel_time(phi, speed,dx=250)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates pandas dataframe with input data\n",
    "def data_gen(i,j,data0):\n",
    "    \n",
    "    d_boundary = np.load('d_boundary.npy')\n",
    "    row_nr = np.load('row_nr.npy')\n",
    "    col_nr = np.load('col_nr.npy')\n",
    "    data_hk = np.loadtxt('hyd_kon')\n",
    "    \n",
    "    data_hk = data_hk[::-1]\n",
    "    hyk = np.flipud((data_hk))\n",
    "    t = travel_time(i,j,data0)\n",
    "    d_well = well_dist(i,j)\n",
    "    d = dist()\n",
    "    \n",
    "    #head_diff = np.reshape(head_differ,(320*440))\n",
    "    dists = np.reshape(d,(320*440))\n",
    "    dist_b = np.reshape(d_boundary,(320*440))\n",
    "    time = np.reshape(t,(320*440))\n",
    "    dist_well = np.reshape(d_well,(320*440))\n",
    "    head0 = np.reshape(data0,(320*440))\n",
    "    hykk = np.reshape(hyk,(320*440))\n",
    "    hykk_l = np.reshape(np.log10(hyk),(320*440))\n",
    "    row = np.reshape(row_nr,(320*440))\n",
    "    col = np.reshape(col_nr,(320*440))\n",
    "    \n",
    "\n",
    "    data_set_t= pd.DataFrame(head0)\n",
    "    \n",
    "    data_set_t.columns = [\"head\"]\n",
    "\n",
    "    #data_set_t['head']=head0   \n",
    "    data_set_t['dist']=dists\n",
    "    data_set_t['time']=time\n",
    "    data_set_t['dist_well']=dist_well\n",
    "    data_set_t['h_cond']=hykk\n",
    "    data_set_t['h_cond_log']=hykk_l\n",
    "    data_set_t['row']=row\n",
    "    data_set_t['col']=col\n",
    "    data_set_t['dist_boundary']=dist_b\n",
    "    data_set_t = data_set_t[(data_set_t[['head']] != -999).all(axis=1)]\n",
    "    data_set_t = data_set_t[(data_set_t[['time']] != 0).all(axis=1)]\n",
    "    data_set_t = data_set_t[(data_set_t[['dist_boundary']] > 750).all(axis=1)]\n",
    "  \n",
    "    return data_set_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scatter(i,j,data0,head_differ):\n",
    "    d_boundary = np.load('d_boundary.npy')\n",
    "    t = travel_time(i,j,data0)\n",
    "    head_diff = np.reshape(head_differ,(320*440))\n",
    "    dist_b = np.reshape(d_boundary,(320*440))\n",
    "    time = np.reshape(t,(320*440))\n",
    "    head0 = np.reshape(data0,(320*440))\n",
    "\n",
    "    \n",
    "\n",
    "    data_set_t= pd.DataFrame(head_diff)   \n",
    "    data_set_t.columns = [\"head_differ\"]\n",
    "\n",
    "    data_set_t['head']=head0   \n",
    "    data_set_t['time']=time\n",
    "    data_set_t['dist_boundary']=dist_b\n",
    "    data_set_t = data_set_t[(data_set_t[['head']] != -999).all(axis=1)]\n",
    "    data_set_t = data_set_t[(data_set_t[['time']] != 0).all(axis=1)]\n",
    "    data_set_t = data_set_t[(data_set_t[['dist_boundary']] > 750).all(axis=1)]\n",
    "    return data_set_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data on hydraulic head changes from well simulations in MODFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path =  os.path.join(\"Well_data_examps\")\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(Path):\n",
    "    for file in f:\n",
    "        if '.npy' in file:\n",
    "            files.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_len = 440\n",
    "col_len = 320\n",
    "data = np.empty((len(files),row_len,col_len))\n",
    "for i in range(len(files)):\n",
    "    dats = np.load(files[i])\n",
    "    data[i,:,:] = dats[3,:,:]\n",
    "    \n",
    "data0 = np.load(os.path.join(\"Well_data_examps/no_pump\",'head_no_pump.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The well locations [row, column] for each simulation are noted below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examps =np.array([[137,182], [157,222], [180, 174], [212,197], [255,221]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import plot_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "model = tf.keras.models.load_model('my_model.h5',compile=False)\n",
    "sc=joblib.load('std_scaler.bin')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'data_select' variable determines what simulation scenario is run - check the 'examps' array for row and column number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = 0 #0,1,2,3 or 4\n",
    "row = examps[data_select,0]\n",
    "col = examps[data_select,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Input data for the network is generated. The input parameters are scaled with a standard scaler and the network is applied to predict hydraulic head changes from the given inputs. The outputs are mean hydraulic head change and standard deviaiton on that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = data_gen(row,col,data0[3,:,:])\n",
    "data_scaled = sc.transform(data_sets.iloc[:,0:6]) \n",
    "t_1 = time()\n",
    "y_hat = model(data_scaled)\n",
    "mean = y_hat.mean()\n",
    "stddev = y_hat.stddev()\n",
    "t_2 = time()\n",
    "\n",
    "print(f'Prediction time {np.round(t_2-t_1,3)} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The predictions are compared to MODFLOW values in the following subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ML = np.empty((row_len,col_len))\n",
    "data_ML.fill(np.nan)\n",
    "data_set = np.array(data_sets.iloc[:,:])\n",
    "\n",
    "rows = data_set[:,-3].astype(int)\n",
    "cols = data_set[:,-2].astype(int)\n",
    "data_ML[rows,cols]=mean[:,0] \n",
    "\n",
    "\n",
    "data_st = np.empty((row_len,col_len))\n",
    "data_st.fill(np.nan)\n",
    "\n",
    "data_st[rows,cols]=stddev[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax3, ax1, ax2) = plt.subplots(1,3)\n",
    "\n",
    "\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(30)\n",
    "\n",
    "c1 = ax1.imshow(data_ML, vmin=0, vmax=1, cmap='hot_r')\n",
    "ax1.set(xlabel='column', ylabel='row',title='Neural network prediction')\n",
    "fig.colorbar(c1,ax = ax1)\n",
    "\n",
    "c2 = ax2.imshow(data_st,cmap='hot_r',vmin=0,vmax=.5)\n",
    "ax2.set(xlabel='column',title='NN Standard deviation')\n",
    "fig.colorbar(c2,ax = ax2)\n",
    "\n",
    "c3 = ax3.imshow(data0[3,:,:]-data[data_select,:,:],cmap='hot_r',vmin=0,vmax=1)\n",
    "ax3.set(xlabel='column',title='MODFLOW prediction')\n",
    "fig.colorbar(c3,ax = ax3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following scatterplot compares the predictions on a 1-1 scale. x-axis shows MODFLOW head change values. y-axis shows predicted head change values from the neural network along with a 95 % confidence interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testi = data_scatter(row,col,data0[3,:,:],(data0[3,:,:]-data[data_select,:,:]))\n",
    "y_testi = y_testi.iloc[:,0]\n",
    "err = 1.96*stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.errorbar(y_testi,mean,yerr=err[:,0],fmt='.', color='b', label='95 % conf')\n",
    "plt.plot(y_testi,mean,'ro', label='Scatter point')\n",
    "plt.plot([y_testi.min(), y_testi.max()], [y_testi.min(), y_testi.max()], 'k--', lw=4)\n",
    "#plt.ylim([0,0.5])\n",
    "#plt.xlim([0,0.5])\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Measured (Flopy)')\n",
    "plt.title('Predicted values with 95% conf')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network compared to MODFLOW in a different scenario by changing the 'data_select' value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
